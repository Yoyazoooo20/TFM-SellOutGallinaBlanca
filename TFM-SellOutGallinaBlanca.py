# -*- coding: utf-8 -*-
"""TFM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t6ThuanLUGrZOMgWsYLwRPLK74G7QR6T

# **Exploratory Data Analysis**
"""

# Cargamos las librerias necesarias
from google.colab import drive
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from prophet import Prophet
from xgboost import XGBRegressor
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression

# Commented out IPython magic to ensure Python compatibility.
# Conectamos el Google Colab con nuestro usuario de Google Drive
drive.mount('/content/drive')
# Ruta de la carpeta que contiene los codigos .py en el Google Drive
# %cd /content/drive/My Drive/TFM/

# Disponemos de dos conjuntos de datos: Los datos de SellOut de dos caldos de Gallina Blanca en Carrefour desde el 2022 hasta 2023, y la temperatura mensual de Italia desde 1990 hasta 2022
# Cargamos los datos de Sellout
df=pd.read_csv('/content/drive/My Drive/TFM/FACT_SELLOUT.csv', sep=';', header=0)
# Cargamos los datos de temperatura de Italia y los visualizamos
temp=pd.read_csv('/content/drive/My Drive/TFM/1901_2022_Italy.csv', sep=',', header=0)

# Analizamos el contenido de los conjuntos de datos y sus dimensiones
print("Dimensiones del conjunto de datos de SellOut:",df.shape)
print("Primeras 5 filas del conjunto de datos:\n",df.head(5))
print("Detalle del conjunto de datos:\n",df.describe())
print("\n")
print("Dimensiones del conjunto de datos de temperaturas:",temp.shape)
print("Primeras 5 filas del conjunto de datos:\n",temp.head(5))

"""Vemos que el conjunto de datos de SellOut contiene la siguiente información:


*   MATERIAL: Nombre del material.
*   YEAR_MONTH: Tiempo en formato AñoMes, desde el Enero del 2022 hasta Marzo del 2023.
*   SRC_ACTIVITY_TYPE: Tipo de venta (En tienda o Online).
*   SRC_DELIVERY_TYPE: Tipo de entrega (En tienda, a casa, o recogida).
*   POSTAL_CODE: Codigo postal de la tienda.
*   SRC_COUNTRY_DESCRIPTION: Nombre del país (Siempre Italia en nuestro caso).
*   SRC_CHAIN_TYPE_DESCRIPTION: Tipo de canal (super, hiper o proxy).
*   SRC_CHAIN_DESCRIPTION: Tipo de Carrefour.
*   SRC_STORE_DESCRIPTION: Dirección de la tienda.
*   SRC_CITY_DESCRIPTION: Ciudad de la tienda.
*   SRC_REGION_DESCRIPTION: Region de la tienda.
*   SRC_SEGMENT_DESCRIPTION: Segmento del material.
*   SALES_UNIT_NUMBER: Volumen de venta.

El conjunto de datos de Temperatura contiene la siguiente información:

*   YEAR: Contiene los años desde 1901 hasta 2022.
*   JAN: Temperaturas del mes de Enero.
*   FEB: Temperaturas del mes de Febrero.
*   .....
*   NOV: Temperaturas del mes de Noviembre.
*   DEC: Temperaturas del mes de Deciembre.
*   El resto son columnas de promedios que no vamos a usar.

"""

# Verificamos que no hay datos nulos en los dos datasets
df.isnull().sum()

# Remplazamos los nulos de la columna de volumen por ceros
df['SALES_UNIT_NUMBER'] = df['SALES_UNIT_NUMBER'].fillna(0)

# Volvemos a comprobar los nulos de df
df.isnull().sum()

temp.isnull().sum()

# Transponemos los datos de las tempraturas de columnas a filas, de manera que cada fila tendrá la temperatura de cada año-mes.
temp_unpivot = pd.melt(temp, id_vars='YEAR', value_vars=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'],
             var_name='MONTH', value_name='TEMP')
temp_unpivot['MONTH'] = temp_unpivot['MONTH'].replace(['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'], ['01','02','03','04','05','06','07','08','09','10','11','12'])
temp_unpivot["YEAR_MONTH"] = temp_unpivot["YEAR"].astype(str) + temp_unpivot["MONTH"]
temp_yearmonth = temp_unpivot[["YEAR_MONTH", "TEMP"]]
print(temp_yearmonth.head(5))

# Como conjunto de entrenamiento tomaremos los datos del 2022, y como conjunto test los datos del 2023
df["YEAR_MONTH"] = df["YEAR_MONTH"].astype(str)
train = df[df["YEAR_MONTH"].str.contains("2022")]
test = df[df["YEAR_MONTH"].str.contains("2023")]
print("Primeras 5 filas del conjunto de entrenamiento:\n",train.head(5))
print("\n")
print("\n")
print("Primeras 5 filas del conjunto de testeo:\n",test.head(5))

# Añadimos las tempraturas al conjunto de entrenamiento
train = train.merge(temp_yearmonth, on='YEAR_MONTH', how='left')
print(train.head(5))

# Analizamos la distribución de los datos por tienda, ciudad y region
plt.figure(figsize=(10,8))
train['SRC_STORE_DESCRIPTION'].value_counts().plot(kind='bar');

train['SRC_CITY_DESCRIPTION'].value_counts().plot(kind='bar');

train['SRC_REGION_DESCRIPTION'].value_counts().plot(kind='bar');

train['SRC_CHAIN_TYPE_DESCRIPTION'].value_counts().plot(kind='bar');

train['SRC_CHAIN_DESCRIPTION'].value_counts().plot(kind='bar');

# Al ver que hay poco historico por tienda de los dos caldos, se crea una nueva variable de Region + tipo de canal de venta
train['REGION_CHAIN_TYPE'] = train['SRC_REGION_DESCRIPTION'] + ' - ' + train['SRC_CHAIN_TYPE_DESCRIPTION']
train['REGION_CHAIN_TYPE'].value_counts().plot(kind='bar');
train.REGION_CHAIN_TYPE.value_counts().sort_index(ascending=False).sort_values(ascending=False)

train['SRC_ACTIVITY_TYPE'].value_counts().plot(kind='bar');

train['SRC_DELIVERY_TYPE'].value_counts().plot(kind='bar');

train.hist(bins = 30, figsize=(20, 20), color = 'r')

from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

#Normalizamos las variables categoricas para calcular la correlacion
train_with_levels = train.copy()
train_with_levels['TEMP'] = train_with_levels['TEMP'].astype(float)
labelencoder=LabelEncoder()
train_with_levels.head(5)
for column in ['MATERIAL','YEAR_MONTH','REGION_CHAIN_TYPE']:
    train_with_levels[column] = labelencoder.fit_transform(train_with_levels[column])

train_with_levels.head(5)

# Se calcula la correlación y se representa su mapa de calor
correlations = train_with_levels[['MATERIAL','YEAR_MONTH','REGION_CHAIN_TYPE','TEMP','SALES_UNIT_NUMBER']].corr()
f, ax = plt.subplots(figsize=(20,20))
sns.heatmap(correlations, annot = True);

sales = temp_yearmonth[temp_yearmonth.YEAR_MONTH.astype(int)>201700]
# store types
plt.rcParams['figure.figsize'] = [28, 26]
sales.plot(x = "YEAR_MONTH", y = "TEMP", fontsize = 30)

decomposition = seasonal_decompose(sales['TEMP'], model = 'additive', period = 12)
decomposition.trend.plot(color = 'blue')

# Creación de la serie temporal para el uso de Prophet en las temperaturas
temp_model = temp_unpivot.copy()
temp_model['ds'] = temp_unpivot['YEAR'].astype(str)+'-'+temp_unpivot['MONTH'].astype(str)+'-01'
temp_model['ds'] = temp_model['ds'].astype('datetime64[ns]')
temp_model_2017 = temp_model[temp_model.YEAR_MONTH.astype(int)>201700]
sns.boxplot(data=temp_model_2017,x='MONTH',y='TEMP')

# se filtran los datos anteriores al 2023 para entrenar el modelo
temp_model_2022 = temp_model_2017[temp_model_2017.YEAR_MONTH.astype(int)<202300]
temp_model_2022['y'] = temp_model_2022['TEMP']
my_model = Prophet(interval_width=0.95, yearly_seasonality=True)
my_model.fit(temp_model_2022[['ds','y']])
future_dates = my_model.make_future_dataframe(periods=3, freq='MS')
future_dates.head()
forecast = my_model.predict(future_dates)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()
plt.rcParams['figure.figsize'] = [28, 26]
plt.figure()
my_model.plot(forecast, uncertainty=True)

# Se calcula la predicción de las temperaturas promedias de Italia de los primeros meses de 2023
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()

my_model.plot(forecast, uncertainty=True)

# Se añaden las temperaturas a los datos de Sell-Out
temp_2022=temp_model_2017[temp_model_2017.YEAR_MONTH.astype(int)>202200]
test_temp = temp_2022.merge(forecast[['ds', 'yhat']], on='ds', how='left')
test_temp.tail(12)
test_temp['ERROR_RELATIVE'] = 100*abs(test_temp.yhat-test_temp.TEMP)/test_temp.TEMP
test_temp['FORECAST']=test_temp['yhat']
test_temp[['YEAR_MONTH', 'TEMP', 'FORECAST', 'ERROR_RELATIVE']].tail(12)

train_group = train_with_levels.groupby(["MATERIAL","YEAR_MONTH","REGION_CHAIN_TYPE","TEMP"], as_index=False)["SALES_UNIT_NUMBER"].sum()

# Se crean dos conjuntos de datos de entrenamiento, uno con las temperaturas y el otro con los meses del 2022
xtrain_yearmonth = train_group[['MATERIAL','YEAR_MONTH','REGION_CHAIN_TYPE']]
xtrain_temp = train_group[['MATERIAL','TEMP','REGION_CHAIN_TYPE']]
ytrain = train_group['SALES_UNIT_NUMBER']
# Se crean los modelos de Gradient Boost
model = XGBRegressor()
model.fit(xtrain_yearmonth, ytrain)
score = model.score(xtrain_yearmonth, ytrain)
model1 = XGBRegressor()
model1.fit(xtrain_temp, ytrain)
score1 = model1.score(xtrain_temp, ytrain)

# El valor de R cuadrado de los modelos
print(score)
print(score1)

# Se normaliza el conjunto de testeo para que sea parecido al conjunto de entrenamiento
test['REGION_CHAIN_TYPE'] = test['SRC_REGION_DESCRIPTION'] + ' - ' + test['SRC_CHAIN_TYPE_DESCRIPTION']
test_with_levels = test.copy()
test_group = test_with_levels.groupby(["MATERIAL","YEAR_MONTH","REGION_CHAIN_TYPE"], as_index=False)["SALES_UNIT_NUMBER"].sum()
forecast['TEMP']=forecast['yhat']
forecast['YEAR_MONTH']= forecast['ds'].map(lambda x: 100*x.year + x.month).astype(str)
test_with_temp = test_group.merge(forecast[['YEAR_MONTH', 'TEMP']], on='YEAR_MONTH', how='left')

for column in ['MATERIAL','YEAR_MONTH','REGION_CHAIN_TYPE']:
    test_with_temp[column] = labelencoder.fit_transform(test_with_temp[column])
test_x = test_with_temp[["MATERIAL","TEMP","REGION_CHAIN_TYPE"]]
test_y=test_with_temp["SALES_UNIT_NUMBER"]
ypred = model1.predict(test_x)

# Se calcula error del primero modelo
mse = mean_squared_error(test_y, ypred)
print("MSE: %.2f" % mse)
print("RMSE: %.2f" % (mse**(1/2.0)))

# Se representa el gráfico de los resultados del primer modelo vs realidad
x_ax = range(len(test_y))
plt.plot(x_ax, test_y, label="original")
plt.plot(x_ax, ypred, label="predicted")

plt.title("XGBoost excluyendo el tiempo")

plt.legend()
plt.show()

# Ánalogamente al primer modelo
test_x1 = test_with_temp[["MATERIAL","YEAR_MONTH","REGION_CHAIN_TYPE"]]
test_y1=test_with_temp["SALES_UNIT_NUMBER"]
ypred1 = model.predict(test_x1)

mse = mean_squared_error(test_y1, ypred1)
print("MSE: %.2f" % mse)
print("RMSE: %.2f" % (mse**(1/2.0)))

x_ax = range(len(test_y1))
plt.plot(x_ax, test_y1, label="original")
plt.plot(x_ax, ypred1, label="predicted")

plt.title("XGBoost excluyendo la temperatura")

plt.legend()
plt.show()

#Punutación o calidad de predicción de cada modelo
model.score(test_x1, test_y1)

model1.score(test_x, test_y)

# Se crea modelo de regresión lineal para cada subconjunto de datos (con temperatura y con los meses)
model_lin = LinearRegression()
model_lin.fit(xtrain_temp, ytrain)
model_lin.score(xtrain_temp, ytrain)

ypred_lin = model_lin.predict(test_x)
x_ax = range(len(test_y1))
plt.plot(x_ax, test_y1, label="original")
plt.plot(x_ax, ypred_lin, label="predicted")

plt.title("Modelo lineal múltiple excluyendo el tiempo")

plt.legend()
plt.show()

model_lin1 = LinearRegression()
model_lin1.fit(xtrain_yearmonth, ytrain)
model_lin1.score(xtrain_yearmonth, ytrain)

ypred_lin1 = model_lin1.predict(test_x1)
x_ax = range(len(test_y1))
plt.plot(x_ax, test_y1, label="original")
plt.plot(x_ax, ypred_lin1, label="predicted")

plt.title("Modelo lineal excluyendo las temperaturas")

plt.legend()
plt.show()

model_lin.score(xtrain_temp, ytrain)

model_lin1.score(xtrain_yearmonth, ytrain)

# Se seleccionan las tres combinanciones de Región - Canal con mayor cantidad de registros de SellOut en 2023
# Para predecir sus ventas mediante el modelo de Series Temporales Prophet
test.REGION_CHAIN_TYPE.value_counts().sort_index(ascending=False).sort_values(ascending=False)

df_prophet_1 = train.copy()
df_prophet_1 = df_prophet_1.loc[df_prophet_1['REGION_CHAIN_TYPE'] == 'Lombardia - SUPERMARKET']
df_prophet_1['YEAR'] = df_prophet_1['YEAR_MONTH'].astype(str).str[:4]
df_prophet_1['MONTH'] = df_prophet_1['YEAR_MONTH'].astype(str).str[4:6]
df_prophet_1['ds'] = df_prophet_1['YEAR'].astype(str)+'-'+df_prophet_1['MONTH'].astype(str)+'-01'
df_prophet_1['ds'] = df_prophet_1['ds'].astype('datetime64[ns]')
df_prophet_1 = df_prophet_1[['ds', 'SALES_UNIT_NUMBER']].rename(columns={'ds': 'ds', 'SALES_UNIT_NUMBER': 'y'})
df_prophet_1 = df_prophet_1.groupby(["ds"], as_index=False)["y"].sum()

test_prophet_1 = test.loc[test['REGION_CHAIN_TYPE'] == 'Lombardia - SUPERMARKET'].copy()
test_prophet_1['YEAR'] = test_prophet_1['YEAR_MONTH'].astype(str).str[:4]
test_prophet_1['MONTH'] = test_prophet_1['YEAR_MONTH'].astype(str).str[4:6]
test_prophet_1['ds'] = test_prophet_1['YEAR'].astype(str)+'-'+test_prophet_1['MONTH'].astype(str)+'-01'
test_prophet_1['ds'] = test_prophet_1['ds'].astype('datetime64[ns]')
test_prophet_group_1 = test_prophet_1.groupby(["ds"], as_index=False)["SALES_UNIT_NUMBER"].sum()

# Ajustar el modelo Prophet
new_model_1 = Prophet()
new_model_1.fit(df_prophet_1)
future_1 = new_model_1.make_future_dataframe(periods=3, freq='MS')

# Realizar la predicción
forecast_1 = new_model_1.predict(future_1)

test_prophet_with_predict_1 = test_prophet_group_1.merge(forecast_1[['ds', 'yhat']], on='ds', how='left')
test_prophet_with_predict_1['ERROR_RELATIVE'] = 100*abs(test_prophet_with_predict_1.yhat-test_prophet_with_predict_1.SALES_UNIT_NUMBER)/test_prophet_with_predict_1.SALES_UNIT_NUMBER
test_prophet_with_predict_1['FORECAST']=test_prophet_with_predict_1['yhat']

forecast_1[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()
plt.rcParams['figure.figsize'] = [28, 26]
plt.figure()
new_model_1.plot(forecast_1, uncertainty=True)

test_prophet_with_predict_1[['ds', 'SALES_UNIT_NUMBER', 'FORECAST', 'ERROR_RELATIVE']].tail(12)

forecast_1

df_prophet_2 = train.copy()
df_prophet_2 = df_prophet_2.loc[df_prophet_2['REGION_CHAIN_TYPE'] == 'Toscana - PROXI']
df_prophet_2['YEAR'] = df_prophet_2['YEAR_MONTH'].astype(str).str[:4]
df_prophet_2['MONTH'] = df_prophet_2['YEAR_MONTH'].astype(str).str[4:6]
df_prophet_2['ds'] = df_prophet_2['YEAR'].astype(str)+'-'+df_prophet_2['MONTH'].astype(str)+'-01'
df_prophet_2['ds'] = df_prophet_2['ds'].astype('datetime64[ns]')
df_prophet_2 = df_prophet_2[['ds', 'SALES_UNIT_NUMBER']].rename(columns={'ds': 'ds', 'SALES_UNIT_NUMBER': 'y'})
df_prophet_2 = df_prophet_2.groupby(["ds"], as_index=False)["y"].sum()

test_prophet_2 = test.loc[test['REGION_CHAIN_TYPE'] == 'Toscana - PROXI'].copy()
test_prophet_2['YEAR'] = test_prophet_2['YEAR_MONTH'].astype(str).str[:4]
test_prophet_2['MONTH'] = test_prophet_2['YEAR_MONTH'].astype(str).str[4:6]
test_prophet_2['ds'] = test_prophet_2['YEAR'].astype(str)+'-'+test_prophet_2['MONTH'].astype(str)+'-01'
test_prophet_2['ds'] = test_prophet_2['ds'].astype('datetime64[ns]')
test_prophet_group_2 = test_prophet_2.groupby(["ds"], as_index=False)["SALES_UNIT_NUMBER"].sum()

# Ajustar el modelo Prophet
new_model_2 = Prophet()
new_model_2.fit(df_prophet_2)
future_2 = new_model_2.make_future_dataframe(periods=3, freq='MS')

# Realizar la predicción
forecast_2 = new_model_2.predict(future_2)

test_prophet_with_predict_2 = test_prophet_group_2.merge(forecast_2[['ds', 'yhat']], on='ds', how='left')
test_prophet_with_predict_2['ERROR_RELATIVE'] = 100*abs(test_prophet_with_predict_2.yhat-test_prophet_with_predict_2.SALES_UNIT_NUMBER)/test_prophet_with_predict_2.SALES_UNIT_NUMBER
test_prophet_with_predict_2['FORECAST']=test_prophet_with_predict_2['yhat']

forecast_2[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()
plt.rcParams['figure.figsize'] = [28, 26]
plt.figure()
new_model_2.plot(forecast_2, uncertainty=True)

test_prophet_with_predict_2[['ds', 'SALES_UNIT_NUMBER', 'FORECAST', 'ERROR_RELATIVE']].tail(12)